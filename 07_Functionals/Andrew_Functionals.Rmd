---
title: "Andrew_Functionals"
author: "Andrew MacDonald"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: yes
    keep_md: TRUE
---

```{r opts}
knitr::opts_chunk$set(error = TRUE, cache = TRUE)
library(ggplot2)
library(tidyr)
library(magrittr)
```


## Exercises 1
### Why are the following two invocations of `lapply()` equivalent?
Because the first element of `mean()` gets interpreted as the value of `trim` **IF** the value of x is already supplied.

```{r mean}
mean(0.5, x = c(0:10,50))
```

### The function below scales a vector so it falls in the range [0, 1]. How would you apply it to every column of a data frame? How would you apply it to every numeric column in a data frame?

```{r scale_vector_lapply}
scale01 <- function(x) {
  rng <- range(x, na.rm = TRUE)
  (x - rng[1]) / (rng[2] - rng[1])
}

mtcars_scale <- mtcars[]
mtcars_scale[] <- lapply(mtcars, scale01)
head(mtcars_scale)

scale_numerics <- function(dat){
  if(is.numeric(dat)){
    scale01(dat)
    } else {
      dat
      }
  }

iris_scale <- iris

iris_scale[] <- lapply(iris, scale_numerics)

head(iris)

try(lapply(iris, scale01))
```

### Use both for loops and `lapply()` to fit linear models to the mtcars using the formulas stored in this list:

```{r modfit}
formulas <- list(
  mpg ~ disp,
  mpg ~ I(1 / disp),
  mpg ~ disp + wt,
  mpg ~ I(1 / disp) + wt
)

mods <- vector("list", length(formulas))

for (i in seq_along(formulas)){
  mods[[i]] <- lm(formulas[[i]], data = mtcars)
  }
```

The `lapply()` method is interesting. normally I would use an anonymous function, but I learned from the examples in this chapter that this is not actually necessary:

```{r lapplymod}
models_mtcars <- lapply(formulas, lm, data = mtcars)
# old way
#lapply(formulas, function(form) lm(form, data = mtcars))
```


### Fit the model `mpg ~ disp` to each of the bootstrap replicates of mtcars in the list below by using a for loop and `lapply()`. Can you do it without an anonymous function?

```{r bootmod}

bootstraps <- lapply(1:10, function(i) {
  rows <- sample(1:nrow(mtcars), rep = TRUE)
  mtcars[rows, ]
})

## for loop

bootstrap_models <- vector("list",length(bootstraps))
for(i in seq_along(bootstraps)){
  bootstrap_models[[i]] <- lm(mpg ~ disp, data = bootstraps[[i]])
  }

## lapply

bootstrap_models_lapply <- lapply(bootstraps, lm, formula = mpg ~ disp)
```

I must say, although I love this approach (avoiding anonymous functions) because of its simple elegance, I have my doubts.  It strikes me as both harder to read and error prone.  Harder to read, because your reader might not remember/know that `data` is the second argument to `lm()` (I had to check, and I've been doing this for years). Error-prone, because you might inadvertently pass the list elements to the wrong argument, and not immediately realize your mistake.

### For each model in the previous two exercises, extract R2 using the function below.

```{r rsq}
rsq <- function(mod) summary(mod)$r.squared

sapply(bootstrap_models_lapply, rsq)

sapply(models_mtcars, rsq)

```

### Use vapply() to Compute the standard deviation of every column in a numeric data frame.

```{r sdcol}
species_abundances <- sample(seq_len(100),size = 5) %>%
  sapply(rpois, n = 20) %>%
  data.frame %>%
  set_names(paste0("sp",1:5))

vapply(species_abundances, sd, numeric(1))

```

### Compute the standard deviation of every numeric column in a mixed data frame. (Hint: you’ll need to use vapply() twice.)

```{r sdnum}
library(dplyr)
site_species <- species_abundances %>% 
  mutate(site = paste0("site",LETTERS[1:5]) %>%
           rep(times = 4))

vapply(site_species[vapply(site_species, is.numeric, logical(1))], sd, numeric(1))

## Equivalently, in magrittr style:
site_species %>%
  vapply(is.numeric, logical(1)) %>%
  site_species[.] %>%
  vapply(sd, numeric(1))

```


### Why is using sapply() to get the class() of each element in a data frame dangerous?
Because many elements will have >1 classes, and`sapply` will silently return a list (you probably wanted a vector, or you would have just used `lapply` directly).

### Use sapply() and an anonymous function to extract the p-value from every trial.

```{r pval}
trials <- replicate(
  100, 
  t.test(rpois(10, 10), rpois(7, 10)),
  simplify = FALSE
)

sapply(trials, function(test) test$p.value)

sapply(trials, '[[', i = "p.value") 
```

### What does replicate() do? What sort of for loop does it eliminate? Why do its arguments differ from lapply() and friends?

replicate is just sapply run over a vector of length `n` (first arg), that evaluates an expression once for each element and then simplifies the result.  
It eliminates for loops which just repeatedly evaluate an expression. Usually for random numbers; I can't think of a reason to use `replicate()` if something isn't random.
The second argument of `replicate()` isn't a function, it's an expression.  That's because it isn't actually *doing* anything with the vector of numbers, unlike the apply family.

```{r replicate}
replicate(5, rnorm(2))

replicate(4, "blue")
```


### Implement a version of lapply() that supplies FUN with both the name and the value of each component.

Not exactly sure what is meant by "component" here, but here goes:

```{r component}
colnum <- c("blue" = 2, "green" = 7)

lapply(colnum, function(x) x/2)
```

ahh, it actually requires a `Map` or mapply solution!
```{r lapply_by_map}
name_val_lapply <- function(X, FUN, ...){
 Map(FUN, names(X), X, ...)
}

funtest <- function(name_of, val_of){
  paste("the value of", name_of, "is", val_of)
}

name_val_lapply(colnum, funtest)

```

### Implement a combination of Map() and vapply() to create an lapply() variant that iterates in parallel over all of its inputs and stores its outputs in a vector (or a matrix). What arguments should the function take?

I am hazy about what is going on here.  IN fact, rereading this section after looking at this question suggests to me that there are two different uses of the word "parallel" going on here: one refers to sending computations to different cores, and the other to the "zipper" action of `Map` | `mapply`.  not sure what do to here?


### Implement mcsapply(), a multicore version of sapply(). Can you implement mcvapply(), a parallel version of vapply()? Why or why not?

my intuition is that `mcvapply` is impossible, since it allocates the vector first and how can you do that with parallel? you probably can't.

In the cheapest move ever, I implement sapply by taking the guts of sapply and changing lapply to mclapply:
```{r mcsapply}

library(parallel)

mcsapply <- function (X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE) 
  {
  FUN <- match.fun(FUN)
  answer <- mclapply(X = X, FUN = FUN, mc.cores = 2, ...)
  if (USE.NAMES && is.character(X) && is.null(names(answer))) 
    names(answer) <- X
  if (!identical(simplify, FALSE) && length(answer)) 
    simplify2array(answer, higher = (simplify == "array"))
  else answer
  }

##pokey example
boot_df <- function(x) x[sample(nrow(x), rep = T), ]
rsquared <- function(mod) summary(mod)$r.square
boot_lm <- function(i) {
  rsquared(lm(mpg ~ wt + disp, data = boot_df(mtcars)))
}


library(microbenchmark)

## this doesn't actually speed anything up
if(FALSE){
microbenchmark(sapply(1:10, boot_lm),
               mcsapply(1:10, boot_lm))
}


```


## Matrix functionals

### How does apply() arrange the output? Read the documentation and perform some experiments.


```{r applytest}
mat <- matrix(rnorm(20), nrow = 5)

apply(mat, 1, summary)

apply(mat, 2, summary)

apply(mtcars, 2, summary)

```

### There’s no equivalent to split() + vapply(). Should there be? When would it be useful? Implement one yourself.

```{r splitandvapply}
pulse <- round(rnorm(22, 70, 10 / 3)) + rep(c(0, 5), c(10, 12))
group <- rep(c("A", "B"), c(10, 12))
pieces <- split(pulse, group)

split_vapply <- function(x, f, FUN, FUN.VALUE, ...){
  pieces <- split(x, f)
  vapply(pieces, FUN = FUN, FUN.VALUE = FUN.VALUE, ...)
}

split_vapply(pulse, group, mean, numeric(1))

```


### Implement a pure R version of split(). (Hint: use unique() and subsetting.) Can you do it without a for loop?

```{r splittr}

split2 <- function(x, f) {
   groups <- unique(as.factor(f))
   out <- vector('list', length(groups))
   names(out) <- levels(groups)
   for (g in groups) {
       out[[g]] <- x[f == g]
   }
   out
}

split2(pulse, group)


split3 <- function(x, f) {
   groups <- unique(f)
   out <- vector('list', length(groups))
   names(out) <- groups
   lapply(groups, function(lev) x[f == lev] )
}


split3(pulse, group)

```

### What other types of input and output are missing? Brainstorm before you look up some answers in the plyr paper.

er, isn't this just the missing blanks in the plyr table?

#### playing with reduce

```{r reducfun}
Reduce(`*`, 1:10)
factorial(10)
microbenchmark(Reduce(`*`, 1:10), factorial(10))
```

```{r fib}
sapply(rep(1,10), Reduce, f = sum)

Reduce(`*`, 1:10, accumulate = TRUE)

simdecay <- function(){
  replicate(10, sample(1:10, 15, replace = T), simplify = FALSE) %>%
  Reduce(intersect, ., accumulate = TRUE) %>%
  sapply(length)
}

replicate(10, simdecay()) %>%
  matplot(type = "l")

```

## Lists and Predicates

### Why isn’t is.na() a predicate function? What base R function is closest to being a predicate version of is.na()?

Its result is as long as its input -- unlike a true predicate, which returns length 1 always

```{r pred}
is.character(c("foo","bar"))
is.na(NaN)
is.na(NA)
is.na(3)

is.na(c(NA,NA))

is.numeric(c("fo","bar"))
```

`anyNA` is closest to a predicate:

```{r napred}
anyNA(c(NA,NA))
anyNA(c("foo","bar"))
```
um in fact it IS a predicate??

### Use Filter() and vapply() to create a function that applies a summary statistic to every numeric column in a data frame.

```{r sumnum}
numsum <- function(dat, sumstat){
  so_numeros <- Filter(is.numeric, dat)
  vapply(so_numeros, sumstat, numeric(1))
}

numsum(iris, sd)
```

### What’s the relationship between which() and Position()? What’s the relationship between where() and Filter()?

`Position()` gives the first instance of TRUE; `which()` gives em all:

```{r relationship}
scramble <- sample(1:5, size = 50, replace = TRUE)
Position(function(x) x == 1, scramble)
which(scramble == 1)
min(which(scramble == 1))
```

`where()` returns a logical vector, while `Filter()` returns the subset that you might produce with it:
```{r makewhere}
where <- function(f, x) {
  vapply(x, f, logical(1))
}
```

### Implement Any(), a function that takes a list and a predicate function, and returns TRUE if the predicate function returns TRUE for any of the inputs. Implement All() similarly.

I can think of a couple of ways to do this. is it cheating to use `any()` and `all()`?

```{r anyall}
AnyAll <- function(FUN){
  function(f, x){
    test <- vapply(x, f, logical(1))
    FUN(test)
    }
}

Any <- AnyAll(any)
All <- AnyAll(all)

tester <- list("foo",1)

Any(is.numeric, tester)
All(is.numeric, tester)
```

Here is less cheap means to do this, stolen from Davor

```{r anyall2}
AnyAll2 <- function(only_if_all = TRUE){
  ## any or all?
  if (only_if_all) {
    testfun <- function(test) Reduce(`&&`, test, only_if_all)
    } else 
      {
        testfun <- function(test) Reduce(`||`, test, only_if_all)
        }
  
  function(f, x){
    test <- vapply(x, f, logical(1))
    testfun(test)
    }
  }

All2 <- AnyAll2()
Any2 <- AnyAll2(FALSE)

Any2(is.numeric, tester)
All2(is.numeric, tester)


AnyAll3 <- function(only_if_all = TRUE){
  ## any or all?
  tests <- c(`||`,`&&`)
  testfun <- function(test) Reduce(tests[[only_if_all + 1]], test, only_if_all)
  
  function(f, x){
    test <- vapply(x, f, logical(1))
    testfun(test)
    }
  }

AnyAll3()(is.numeric, tester)
AnyAll3(FALSE)(is.numeric, tester)
```

### Implement the span() function from Haskell: given a list x and a predicate function f, span returns the location of the longest sequential run of elements where the predicate is true. (Hint: you might find rle() helpful.)
Building off of `where()`
```{r spanR}
where <- function(f, x) {
  vapply(x, f, logical(1))
}

span <- function(f, x){
  logivec <- where(f = f, x = x)
  runs <- rle(logivec)
  trues <- runs$lengths[runs$values]
  longest <- max(trues)[1] # find the first long sequence only
  start.longest <- which(runs$lengths == longest)
  browser()
  start.longest + seq_len(longest)
}

green30 <- replicate(47, sample(list("green",30), size = 1, prob = c(0.7, 0.3)))

span(is.character, green30)

```

## mathematical functions

### Implement arg_max(). It should take a function and a vector of inputs, and return the elements of the input where the function returns the highest value. For example, arg_max(-10:5, function(x) x ^ 2) should return -10. arg_max(-5:5, function(x) x ^ 2) should return c(-5, 5). Also implement the matching arg_min() function.

```{r arg_maxmin}

arg_maxmin <- function(FUN = max) {
  arg_max <- function(vec, f){
    vals <- f(vec)
    crit <- FUN(vals)
    vec[vals %in% crit]
    }
  }

arg_max <- arg_maxmin()

arg_max(-10:5, function(x) x ^ 2)
arg_max(-5:5, function(x) x ^ 2)


arg_min <- arg_maxmin(min)
arg_min(-10:5, function(x) - x ^ 2)
arg_min(-5:5, function(x) - x ^ 2)
```

## CHALLENGE

first the fixed point procedure

```{r fixedpoint}

running_diff <- function(x){
  tot <- length(x)
  abs(x[-tot] - x[-1])
  }

fixed_point <- function(f, tries, init = 1){
  fvec <- replicate(n = tries, expr = f, simplify = FALSE)
  Reduce(function(f1,f2) f2(f1), x = fvec, init = init, accumulate = TRUE)
  }

check_tol <- function(fpoints, rdiff = running_diff, tol = 0.00001){
  passing_tol <- vapply(rdiff(fpoints), `<`, y = tol, logical(1))
  if(!any(passing_tol)) message("you need more tries!!")
  }

check_tol(fixed_point(cos, 30, tries = 10))

fpoint_plot <- function(f, tries){
  fixingpoints <- fixed_point(f = f, tries = tries)
  qplot(x = 0:tries, y = fixingpoints, geom = "path",
      main = paste0("value of approximation is ", fixingpoints[length(fixingpoints)]),
      xlab = "successive interations", ylab = "Approximations") + theme_bw()
}

fpoint_plot(cos, 30)

fpoint_plot(function(x) cos(x) + sin(x), 30)

## impossible; will never converge:
fpoint_plot(function(x) 5 / x, 300)

## but with slight modification..
fpoint_plot(function(x) (x + 5 / x) / 2, 400)

```


The loveliest of numbers, the Golden Ratio itself:

```{r GoldenRatio}
fpoint_plot(function(x) 1 + 1/x, 50)
```

## 1.36 the effect of damping

```{r damping_log}

fun1 <- function(x) ((log(1000) / log(x)) + x) / 2
fun2 <- function(x) log(1000) / log(x)

data.frame(ntries = 0:40, 
           f1 = fixed_point(fun1, 40, init = 2.5),
           f2 = fixed_point(fun2, 40, init = 2.5)) %>%
  gather(fun, approx, f1:f2) %>%
  ggplot(aes(x = ntries, y = approx, colour = fun)) + geom_point() + geom_path() + theme_bw()

``` 

### recursive fractions
```{r inverse_golden}
frac_maker <- function(n, d){
  force(n)
  force(d)
  function(x) n / (d + x)
  }
  

cont_frac <- function(Ns, Ds, frac_fun = frac_maker){
  Ns <- rev(Ns)
  Ds <- rev(Ds)
  funs <- Map(frac_fun, Ns, Ds)
  Reduce(function(f1,f2) f2(f1), x = funs, init = 0)
  }

ans <- cont_frac(Ns = rep(1,40), Ds = rep(1, 40))

1/ans
```

### 1.38 Euler's number
```{r euler}

denominator <- function(k){
  nums <- lapply(seq_len(k)*2, function(x) c(1, 1, x))
  out <- do.call(c, nums)
  out[-1]
}

cont_frac(Ds = denominator(20), Ns = rep(1, 3 * 20 -1))

```

### let's do $pi$ ! 

There is another continued fraction on Wikipedia, in the [page for Euler](http://en.wikipedia.org/wiki/Euler%27s_continued_fraction_formula)

```{r pi_time}
pi_numerator <- function(k){
  exps <- seq(from = 1, length.out = k, by = 2) ^ 2
  c(4, exps)
}

cont_frac(Ds = c(1, rep(2, 200)), Ns = pi_numerator(200))
```

It might be fun to contrast the speed of convergence of some of these fractions for [transcendental numbers](http://en.wikipedia.org/wiki/Generalized_continued_fraction#Transcendental_functions_and_numbers). 

### Lambert's tangent line

This is different from all previous examples, because here the series that form numerator and denominator are a function of $x$:

```{r }

frac_maker_minus <- function(n, d){
  force(n)
  force(d)
  function(x) n / (d - x)
  }

tan_cf <- function(x, k){
  numerators <- rep(x, k - 1) ^ 2
  numerators <- c(x, numerators)
  denominators <- seq(from = 1, by = 2, length.out = k)
  cont_frac(Ns = numerators, Ds = denominators, frac_fun = frac_maker_minus)
}

tan_cf(pi*0.2, 20)

tan(pi*0.2)
```

## Smaller and Larger

Let's start with the `NA` function:
```{r}
rm_na <- function(x, y, identity) {
  if (is.na(x) && is.na(y)) {
    identity
  } else if (is.na(x)) {
    y
  } else {
    x
  }
}

rm_na(3,4,Inf)
rm_na(3,NA,Inf)
rm_na(NA,4,Inf)
rm_na(NA,NA,Inf)

smaller <- function(x, y, na.rm = TRUE){
  if(na.rm && (is.na(x) || is.na(y))) {
    rm_na(x, y, Inf)
    } else {
      stopifnot(!identical(x, y))
      test <- (x - y) < 0
      if(test) x else y
      }
  
  }

x <- 4
y <- 5


```


## Table of Functions

**variant** | `and` | `or` | `add` | `multiply` | `smaller` | `larger`
------------|-------|------|-------|------------|-----------|---------
binary  | `&&`    |    `||`   |   `+`    |  `*`     |               |
reducing  |  `all`  |   `any`    |   `sum`    |       |               |
vectorized  |  `&`   |    `|`   |   `+`    |  `*`     |               |
array  |     |       |   `+`     |      |               |

## reading notes 

I really liked this simple example of a functional to make randomized versions of common summary functions:

```{r normal_randomizer}
randomise <- function(f) f(runif(1e3))
randomise(mean)
#> [1] 0.5115665
randomise(mean)
#> [1] 0.503939
randomise(sum)

replicate(500,randomise(sum)) %>%
  data.frame(x = .) %>%
  ggplot(aes(x = x)) + geom_density()
```

