---
title: "Andrew -- Functions"
author: "Andrew MacDonald"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: yes
    keep_md: TRUE
---

```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(error = TRUE)
```


```{r}
library(dplyr)
library(pryr)
library(magrittr)
```

## Excercises

### Given a function, like `"mean"`, `match.fun()` lets you find a function. Given a function, can you find its name? Why doesn't that make sense in R?

Because functions don't need to have any names at all, or could have all kinds of names (including aliases), so I can't even imagine how you'd do that.

###  Use `lapply()` and an anonymous function to find the coefficient of variation (the standard deviation divided by the mean) for all columns in the `mtcars` dataset

```{r}
sapply(mtcars, function(dat) sd(dat) / mean(dat) )
```

### Use `integrate()` and an anonymous function to find the area under the curve for the following functions. Use [Wolfram Alpha](http://www.wolframalpha.com/) to check your answers.

1. `y = x ^ 2 - x`, x in [0, 10]
```{r}
integrate(function(x) x ^ 2 - x, 0, 10)
```

1. `y = sin(x) + cos(x)`, x in [-$\pi$, $\pi$]

```{r}
integrate(function(x) sin(x) + cos(x), - pi, pi)
```
**mathworld says this should be 0.00318531. What went wrong?**

1. `y = exp(x) / x`, x in [10, 20]
```{r}
integrate(function(x) exp(x) / x, 10, 20)
```
**correct**

### Review your own code

Here is an example of a `magrittr` pipeline with a multiline anonymous function in it. is it horrible?

```
ctrl_single_pair %>% 
  group_by(resp) %>%
  do(anova_ord = aov(val ~ treatment, data = .)) %>%
  function(g) {
    g %>% 
      extract2("anova_ord") %>% 
      set_names(g %>% extract2("resp"))
    } %>%
  lapply(TukeyHSD) %>%
  lapply(function(x) x[["treatment"]]) %>%
  lapply(as.data.frame) %>%
  lapply(function(x) data.frame(comparison = row.names(x),x)) %>%
  function(m) {
    comps <- rbind_all(m)
    r <- names(m) %>% rep(times = sapply(m,nrow) %>% as.numeric)
    data.frame(r,comps)
    } %>% 
  select(response = r, comparison:p.adj) %>%
  mutate(response = response %>% as.character %>% trtnames[.]) %>%
  xtable %>% 
  print(include.rownames = FALSE, size = 8, comment = FALSE)
```

## Exercises 2
  
### Why are functions created by other functions called closures? 
Because they *enclose* the environment in which they were created

### What does the following statistical function do? What would be a better name for it? (The existing name is a bit of a hint.)

```{r}
bc <- function(lambda) {
  if (lambda == 0) {
    function(x) log(x)
    } else {
      function(x) (x ^ lambda - 1) / lambda
      }
  }
```

the function `bc` is a function factory that has a single argument, `lambda`. it either returns the function `log(x)` (if `lambda` is 0) or the polynomial `(x ^ lambda - 1) / lambda` otherwise.  
Some creative Googling reveals that this is the [Box-Cox Transformation](http://onlinestatbook.com/2/transformations/box-cox.html), so I'd probably call this function `box_cox`.

### What does `approxfun()` do? What does it return?
```{r}
#?approxfun
```
`approxfun` creates a closure function which remembers the data on which `approxfun` was called. This function interpolates the data that was used to create it. Neat!

### What does `ecdf()` do? What does it return?
`ecdf()` is the empirical cumulative distribution function, which I'm going to guess is also a function factory that makes a closure:
```{r}
x <- rnorm(12)
Fn <- ecdf(x)
is.function(Fn) # it's a function!
plot(Fn)
```

### Create a function that creates functions that compute the ith central moment of a numeric vector.

```{r}
moment <- function(i){
  function(x) {
    mean((x - mean(x)) ^ i)
    }
  }
```

Test it out

```{r}
m1 <- moment(1)
m2 <- moment(2)

x <- runif(100)
stopifnot(all.equal(m1(x), 0))
stopifnot(all.equal(m2(x), var(x) * 99 / 100))
```

### Create a function pick() that takes an index, i, as an argument and returns a function with an argument x that subsets x with i.

```{r}
pick <- function(index) function(x) x[[index]]

all.equal(lapply(mtcars, pick(5)),
          lapply(mtcars, function(x) x[[5]]))
```

## Exercises 3
### Implement a summary function that works like base::summary(), but uses a list of functions.
I assume we are making a version of `summary` as it works on data.frames : 
```{r}
summary(iris)
```

```{r}
## make a list of functions
funs <- list(
  "Min." = min,
  "1st Qu." = function(x) quantile(x, probs = 0.25),
  "Median" = median,
  "Mean" = mean,
  "3rd Qu" =  function(x) quantile(x, probs = 0.75),
  "Max." = max)

summary_andrew <- function(flist = funs){
  function(data) {
    lapply(data, function(d) sapply(flist, function(f) f(d)))
  }
  }
## do that list to each element of a dataframe/ list
summary_andrew()(mtcars)
```
Is there a pretty way to use `mapply` here ?

### Which of the following commands is equivalent to with(x, f(z))?
c, unless you've attached it (in which case it would be d) so I guess e

## Exercises 4

### Instead of creating individual functions (e.g., midpoint(), trapezoid(), simpson(), etc.), we could store them in a list. If we did that, how would that change the code? Can you create the list of functions from a list of coefficients for the Newton-Cotes formulae?

First, run all of Hadley's functions : 
```{r}
midpoint <- function(f, a, b) {
  (b - a) * f((a + b) / 2)
}

trapezoid <- function(f, a, b) {
  (b - a) / 2 * (f(a) + f(b))
}

midpoint(sin, 0, pi)
#> [1] 3.141593
trapezoid(sin, 0, pi)
#> [1] 1.923671e-16

composite <- function(f, a, b, n = 10, rule) {
  points <- seq(a, b, length = n + 1)

  area <- 0
  for (i in seq_len(n)) {
    area <- area + rule(f, points[i], points[i + 1])
  }

  area
}

composite(sin, 0, pi, n = 10, rule = midpoint)
#> [1] 2.008248
composite(sin, 0, pi, n = 10, rule = trapezoid)

simpson <- function(f, a, b) {
  (b - a) / 6 * (f(a) + 4 * f((a + b) / 2) + f(b))
}

boole <- function(f, a, b) {
  pos <- function(i) a + i * (b - a) / 4
  fi <- function(i) f(pos(i))

  (b - a) / 90 *
    (7 * fi(0) + 32 * fi(1) + 12 * fi(2) + 32 * fi(3) + 7 * fi(4))
}

composite(sin, 0, pi, n = 10, rule = simpson)
#> [1] 2.000007
composite(sin, 0, pi, n = 10, rule = boole)
#> [1] 2



newton_cotes <- function(coef, open = FALSE) {
  n <- length(coef) + open

  function(f, a, b) {
    pos <- function(i) a + i * (b - a) / n
    points <- pos(seq.int(0, length(coef) - 1))

    (b - a) / sum(coef) * sum(f(points) * coef)
  }
}

boole <- newton_cotes(c(7, 32, 12, 32, 7))
milne <- newton_cotes(c(2, -1, 2), open = TRUE)
composite(sin, 0, pi, n = 10, rule = milne)
#> [1] 1.993829
```

Now we can put all the premade functions in a list, and run an anonymous wrapper for `composite()` over it:

```{r}
rulelist <- list(
  midpoint = midpoint,
  trapezoid = trapezoid,
  simpson = simpson,
  boole = boole
  )

lapply(rulelist, function(r) composite(sin, 0, pi, n = 10, rule = r))

```

Are they really different speeds?

```{r}
rulerunner <- function(listrule) {
  force(listrule)
  function() composite(sin, 0, pi, n = 10, rule = listrule)
  }

library(microbenchmark)

lapply(rulelist, rulerunner) %>%
  microbenchmark(list = .)
```

#### making a list from the newton-cotes formula

```{r}
1:5 %>%
  lapply(function(x) {
    force(x) 
    newton_cotes(coef = x)
    }) %>%
  lapply(rulerunner) %>%
  lapply(function(f) f())
```


```{r}
test <- 1:5 %>%
  lapply(function(x) {
    force(x) 
    newton_cotes(coef = x)
    })

unenclose(test[[1]])



```

